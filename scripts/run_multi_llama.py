import copy
import glob
import json
import os
import argparse
from pathlib import Path
from datetime import datetime
import random
import subprocess
import ai2thor.controller

from openai import OpenAI
client = OpenAI(api_key=Path('llama_api_key.txt').read_text(), base_url="https://api.llama-api.com")

import sys
sys.path.append(".")

import resources.actions as actions
import resources.robots as robots


def LM(prompt, llama_version, max_tokens=128, temperature=0, stop=None, logprobs=1, frequency_penalty=0, isAllocate=False):
    
    response = client.chat.completions.create(model=llama_version, 
                                            messages=prompt, 
                                            max_tokens=max_tokens, 
                                            temperature=temperature, 
                                            frequency_penalty = frequency_penalty,
                                            stream=False)
    content = response.choices[0].message.content.strip()

    if not isAllocate and '```python' in content:
        content = content.split('```python')[1].split('```')[0]

    return response, content.strip()

def set_api_key(openai_api_key):
    client.api_key = Path(openai_api_key + '.txt').read_text()

# Function returns object list with name and properties.
def convert_to_dict_objprop(objs, obj_mass):
    objs_dict = []
    for i, obj in enumerate(objs):
        obj_dict = {'name': obj , 'mass' : obj_mass[i]}
        # obj_dict = {'name': obj , 'mass' : 1.0}
        objs_dict.append(obj_dict)
    return objs_dict

def get_ai2_thor_objects(floor_plan_id):
    # connector to ai2thor to get object list
    controller = ai2thor.controller.Controller(scene="FloorPlan"+str(floor_plan_id))
    obj = list([obj["objectType"] for obj in controller.last_event.metadata["objects"]])
    obj_mass = list([obj["mass"] for obj in controller.last_event.metadata["objects"]])
    controller.stop()
    obj = convert_to_dict_objprop(obj, obj_mass)
    return obj

def decompose_task(test_tasks, prompt, llama_version):
    decomposed_plan = []
    for task in test_tasks:
        curr_prompt =  f"{prompt}\n\n# Task Description: {task}"        
        messages = [{"role": "user", "content": curr_prompt}]
        _, text = LM(messages, llama_version, max_tokens=1300, frequency_penalty=0.0)
        decomposed_plan.append(text)
    return decomposed_plan

def allocate_robots(decomposed_plan, prompt, available_robots, objects_ai, llama_version):
    allocated_plan = []
    for i, plan in enumerate(decomposed_plan):
        no_robot  = len(available_robots[i])
        curr_prompt = prompt + plan
        curr_prompt += f"\n# TASK ALLOCATION"
        curr_prompt += f"\n# Scenario: There are {no_robot} robots available, The task should be performed using the minimum number of robots necessary. Robots should be assigned to subtasks that match its skills and mass capacity. Using your reasoning come up with a solution to satisfy all contraints."
        curr_prompt += f"\n\nrobots = {available_robots[i]}"
        curr_prompt += f"\n{objects_ai}"
        curr_prompt += f"\n\n# IMPORTANT: The AI should ensure that the robots assigned to the tasks have all the necessary skills to perform the tasks. IMPORTANT: Determine whether the subtasks must be performed sequentially or in parallel, or a combination of both and allocate robots based on availablitiy. "
        curr_prompt += f"\n# SOLUTION  \n"

        messages = [{"role": "system", "content": "You are a Robot Task Allocation Expert. Determine whether the subtasks must be performed sequentially or in parallel, or a combination of both based on your reasoning. In the case of Task Allocation based on Robot Skills alone - First check if robot teams are required. Then Ensure that robot skills or robot team skills match the required skills for the subtask when allocating. Make sure that condition is met. In the case of Task Allocation based on Mass alone - First check if robot teams are required. Then Ensure that robot mass capacity or robot team combined mass capacity is greater than or equal to the mass for the object when allocating. Make sure that condition is met. In both the Task Task Allocation based on Mass alone and Task Allocation based on Skill alone, if there are multiple options for allocation, pick the best available option by reasoning to the best of your ability."},{"role": "system", "content": "You are a Robot Task Allocation Expert"},{"role": "user", "content": curr_prompt}]
        _, text = LM(messages, llama_version , max_tokens=400, frequency_penalty=0.69, isAllocate=True)

        allocated_plan.append(text)
    return allocated_plan

def generate_code(decomposed_plan, allocated_plan, prompt, available_robots, llama_version):
    code_plan = []
    for i, (plan, solution) in enumerate(zip(decomposed_plan, allocated_plan)):
        curr_prompt = prompt + plan
        curr_prompt += f"\n# TASK ALLOCATION"
        curr_prompt += f"\n\nrobots = {available_robots[i]}"
        curr_prompt += solution
        curr_prompt += f"\n# CODE Solution  \n"
        
        messages = [{"role": "system", "content": "You are a Robot Task Allocation Expert"},{"role": "user", "content": curr_prompt}]
        _, text = LM(messages, llama_version, max_tokens=1400, frequency_penalty=0.4)

        code_plan.append(text)
    return code_plan

def review_code(decomposed_plan, allocated_plan, code_plan, prompt, available_robots, llama_version):
    feedbacks = []
    for i, (plan, solution, code) in enumerate(zip(decomposed_plan, allocated_plan, code_plan)):
        curr_prompt = prompt + "this is the task: ###" + plan + "###"
        curr_prompt += f"\n# And this is the TASK ALLOCATION: ###"
        curr_prompt += f"\n\nrobots = {available_robots[i]}"
        curr_prompt += solution + "###"
        curr_prompt += f"\n# This is the code Solution  : ###" + code + "###"
        role_content = "You are a Robot Task Planning Expert. You are given a task, a solution(decomposed plan and allocated plan), and a code. You need to review those plans and code and provide feedback. The feedback should be in the form of a list of suggestions for the code."
        messages = [{'role':'system', 'content': role_content}, {"role": "user", "content": curr_prompt}]

        _, feedback = LM(messages, llama_version, max_tokens=500, frequency_penalty=0.4)

        feedbacks.append(feedback)
    return feedbacks

def modify_code(original_code_plan, decomposed_plan, allocated_plan,feedbacks, prompt, available_robots, llama_version):
    new_code_plan = []
    for i, (plan, solution, feedback, original_code) in enumerate(zip(decomposed_plan, allocated_plan, feedbacks, original_code_plan)):
        curr_prompt = prompt + plan
        curr_prompt += f"\n# TASK ALLOCATION"
        curr_prompt += f"\n\nrobots = {available_robots[i]}"
        curr_prompt += solution
        curr_prompt += f"\n# This is the original CODE Solution  \n" + original_code
        curr_prompt += f"\n# This is the feedback on the original CODE Solution  \n" + feedback
        role_content = 'You are a Robot Task Allocation Expert. And You are given a task, a solution, and the feedback on the previous plan. Now you need to based on the feedback, modify the code to make it better.'
        messages = [{"role": "system", "content": role_content},{"role": "user", "content": curr_prompt}]
        _, text = LM(messages, llama_version, max_tokens=1400, frequency_penalty=0.4)

        new_code_plan.append(text)
    return new_code_plan




if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--floor-plan", type=int, required=True)
    parser.add_argument("--openai-api-key-file", type=str, default="llama_api_key")
    parser.add_argument("--llama-version", type=str, default="llama3.3-70b", 
                        choices=['llama3.1-405b', 'llama3.3-70b', 'llama3.1-70b', 'llama3.1-8b', 'deepseek-r1', 'deepseek-v3', 'mixtral-8x22b-instruct', 'gemma2-27b'])
    
    parser.add_argument("--prompt-decompse-set", type=str, default="train_task_decompose", 
                        choices=['train_task_decompose', 'train_task_decompose_llama'])
    
    parser.add_argument("--prompt-allocation-set", type=str, default="train_task_allocation", 
                        choices=['train_task_allocation', 'train_task_allocation_llama'])
    
    parser.add_argument("--test-set", type=str, default="final_test", 
                        choices=['final_test'])
    
    parser.add_argument("--log-results", type=bool, default=True)
    
    args = parser.parse_args()

    
    if not os.path.isdir(f"./logs/"):
        os.makedirs(f"./logs/")
        
    # read the tasks        
    test_tasks = []
    robots_test_tasks = []  
    gt_test_tasks = []    
    trans_cnt_tasks = []
    max_trans_cnt_tasks = []  
    with open (f"./data/{args.test_set}/FloorPlan{args.floor_plan}.json", "r") as f:
        for line in f.readlines():
            test_tasks.append(list(json.loads(line).values())[0])
            robots_test_tasks.append(list(json.loads(line).values())[1])
            gt_test_tasks.append(list(json.loads(line).values())[2])
            trans_cnt_tasks.append(list(json.loads(line).values())[3])
            max_trans_cnt_tasks.append(list(json.loads(line).values())[4])
                    
    print(f"\n----Test set tasks----\n{test_tasks}\nTotal: {len(test_tasks)} tasks\n")
    # prepare list of robots for the tasks
    available_robots = []
    for robots_list in robots_test_tasks:
        task_robots = []
        for i, r_id in enumerate(robots_list):
            rob = robots.robots [r_id-1]
            # rename the robot
            rob['name'] = 'robot' + str(i+1)
            task_robots.append(rob)
        available_robots.append(task_robots)
        
    
    ######## Train Task Decomposition ########
        
    # prepare train decompostion demonstration for ai2thor samples
    prompt = "These are the skills and the objects that the robot can perform or interact with: " 
    prompt += f"from skills import " + actions.ai2thor_actions
    prompt += f"\nimport time"
    prompt += f"\nimport threading"
    objects_ai = f"\n\nobjects = {get_ai2_thor_objects(args.floor_plan)}"
    prompt += objects_ai
    
    # read input train prompts
    decompose_prompt_file = open(os.getcwd() + "/data/pythonic_plans/" + args.prompt_decompse_set + ".py", "r")
    decompose_prompt = decompose_prompt_file.read()
    decompose_prompt_file.close()
    
    prompt += "\n\n The following is the sample code for the solution, please follow the same structure and format:" + decompose_prompt
    
    print ("Generating Decompsed Plans...")
    decomposed_plan = decompose_task(test_tasks, prompt, args.llama_version)
  
    print ("Generating Allocation Solution...")

    ######## Train Task Allocation - SOLUTION ########
    prompt = "These are the skills and the objects that the robot can perform or interact with: " 
    prompt += f"from skills import " + actions.ai2thor_actions
    prompt += f"\nimport time"
    prompt += f"\nimport threading"
    
    prompt_file = os.getcwd() + "/data/pythonic_plans/" + args.prompt_allocation_set + "_solution.py"
    allocated_prompt_file = open(prompt_file, "r")
    allocated_prompt = allocated_prompt_file.read()
    allocated_prompt_file.close()
    
    prompt += "\n\n The following is the sample solution of an allocation plan, please follow the same structure and format:" + allocated_prompt + "\n\n"
    allocated_plan = allocate_robots(decomposed_plan, prompt, available_robots, objects_ai, args.llama_version)
    
    ######## Train Task Allocation - CODE Solution ########
    print ("Generating Code Solution...")
    prompt = f"from skills import " + actions.ai2thor_actions
    prompt += f"\nimport time"
    prompt += f"\nimport threading"
    prompt += objects_ai
    
    prompt += f"\n\n# The following is the sample code for the solution: ###"
    prompt_file1 = os.getcwd() + "/data/pythonic_plans/" + args.prompt_allocation_set + "_code.py"
    code_prompt_file = open(prompt_file1, "r")
    code_prompt = code_prompt_file.read()
    code_prompt_file.close()
    
    prompt_file2 = os.getcwd() + "/data/pythonic_plans/train_final_exe_plan.py"
    final_exe_plan_file = open(prompt_file2, "r")
    final_exe_plan = final_exe_plan_file.read()
    final_exe_plan_file.close()

    prompt += "\n\n" + code_prompt + "\n\n"
    prompt += "\n\n" + final_exe_plan + "\n\n"
    
    code_plan = generate_code(decomposed_plan, allocated_plan, prompt, available_robots, args.llama_version)

    ######## Train Review Process - feedback ########
    print ("Generating Feedback...")
    prompt = "These are the skills and the objects that the robot can perform or interact with: " 
    prompt += f"from skills import " + actions.ai2thor_actions
    prompt += f"\nimport time"
    prompt += f"\nimport threading"
    prompt += objects_ai
    
    # prompt += f"\n\n# The following is the sample code for the solution: ###"
    # prompt_file1 = os.getcwd() + "/data/pythonic_plans/" + args.prompt_allocation_set + "_code.py"
    # code_prompt_file = open(prompt_file1, "r")
    # code_prompt = code_prompt_file.read()
    # code_prompt_file.close()

    # prompt_file2 = os.getcwd() + "/data/pythonic_plans/train_final_exe_plan.py"
    # final_exe_plan_file = open(prompt_file2, "r")
    # final_exe_plan = final_exe_plan_file.read()
    # final_exe_plan_file.close()

    # prompt += "\n\n" + code_prompt + "\n\n"
    # prompt += "\n\n" + final_exe_plan + "\n\n"

    feedbacks = review_code(decomposed_plan, allocated_plan, code_plan, prompt, available_robots, args.llama_version)

    ######## Train Modify Code - Modified CODE Solution ########
    print ("Modifying Code and generating final code solution...")
    prompt = "These are the skills and the objects that the robot can perform or interact with: " 
    prompt += f"from skills import " + actions.ai2thor_actions
    prompt += f"\nimport time"
    prompt += f"\nimport threading"
    prompt += objects_ai
    
    prompt += f"\n\n# The following is the sample code for the solution: ###"
    prompt_file1 = os.getcwd() + "/data/pythonic_plans/" + args.prompt_allocation_set + "_code.py"
    code_prompt_file = open(prompt_file1, "r")
    code_prompt = code_prompt_file.read()
    code_prompt_file.close()

    prompt_file2 = os.getcwd() + "/data/pythonic_plans/train_final_exe_plan.py"
    final_exe_plan_file = open(prompt_file2, "r")
    final_exe_plan = final_exe_plan_file.read()
    final_exe_plan_file.close()

    prompt += "\n\n" + code_prompt + "\n\n"
    prompt += "\n\n" + final_exe_plan + "\n\n"
    new_code_plan = modify_code(code_plan, decomposed_plan, allocated_plan, feedbacks, prompt, available_robots, args.llama_version)

    
    # save generated plans
    print("Storing generated plans...")
    exec_folders = []
    if args.log_results:
        line = {}
        now = datetime.now() # current date and time
        date_time = now.strftime("%m-%d-%Y-%H-%M-%S")
        
        for idx, task in enumerate(test_tasks):
            task_name = "{fxn}".format(fxn = '_'.join(task.split(' ')))
            task_name = task_name.replace('\n','')
            folder_name = f"{task_name}_plans_multi_{args.llama_version}_{date_time}"
            exec_folders.append(folder_name)
            
            os.mkdir("./logs/"+folder_name)
     
            with open(f"./logs/{folder_name}/log.txt", 'w') as f:
                f.write(task)
                f.write(f"\n\nGPT Version: {args.llama_version}")
                f.write(f"\n\nFloor Plan: {args.floor_plan}")
                f.write(f"\n{objects_ai}")
                f.write(f"\nrobots = {available_robots[idx]}")
                f.write(f"\nground_truth = {gt_test_tasks[idx]}")
                f.write(f"\ntrans = {trans_cnt_tasks[idx]}")
                f.write(f"\nmax_trans = {max_trans_cnt_tasks[idx]}")

            with open(f"./logs/{folder_name}/decomposed_plan.py", 'w') as d:
                d.write(decomposed_plan[idx])
                
            with open(f"./logs/{folder_name}/allocated_plan.py", 'w') as a:
                a.write(allocated_plan[idx])
                
            with open(f"./logs/{folder_name}/original_code_plan.py", 'w') as x:
                x.write(code_plan[idx])

            with open(f"./logs/{folder_name}/feedbacks.py", 'w') as b:
                b.write(feedbacks[idx])

            with open(f"./logs/{folder_name}/code_plan.py", 'w') as c:
                c.write(new_code_plan[idx])
            
            
            